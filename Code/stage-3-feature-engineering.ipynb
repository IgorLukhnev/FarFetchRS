{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Проект команды 306 - Проектный семинар - №3 (Извлечение признаков)\n\nСостав команды:\n\n1. Алиев Хайрутдин Аллилович\n2. Зубов Дмитрий Сергеевич\n3. Курбанов Иван Сергеевич\n4. Лухнев Игорь Дмитриевич\n5. Шишков Максим Алексеевич\n\n## TL;DR\n---\nВ данном документе мы проводим применение различных предобученных нейронных сетей для извлечения признаков из картинок.\n\n---\n\n## Предварительные зависимости\nВ следующей ячейке будут установлены необходимые библиотеки через `pip`","metadata":{}},{"cell_type":"code","source":"# Use !pip install -q [your-package]\n!pip install -q PyGithub\n!pip install -q fsspec","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:52:39.072140Z","iopub.execute_input":"2022-03-21T23:52:39.072457Z","iopub.status.idle":"2022-03-21T23:52:56.709546Z","shell.execute_reply.started":"2022-03-21T23:52:39.072373Z","shell.execute_reply":"2022-03-21T23:52:56.708732Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Следующая ячейка для импорта установленных пакетов в проект","metadata":{}},{"cell_type":"code","source":"# use aliases for long names\nimport os\nimport requests\nfrom github import Github as gh\nfrom getpass import getpass\nimport re\nimport pandas as pd\nimport numpy as np\nimport base64\nfrom io import StringIO\nfrom pathlib import Path\nfrom PIL import Image\nimport torch\nimport torchvision\nfrom tqdm.auto import tqdm\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom sklearn.metrics import accuracy_score\nfrom torchvision import transforms\nimport os\nimport random\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:52:56.712177Z","iopub.execute_input":"2022-03-21T23:52:56.712446Z","iopub.status.idle":"2022-03-21T23:52:59.386646Z","shell.execute_reply.started":"2022-03-21T23:52:56.712411Z","shell.execute_reply":"2022-03-21T23:52:59.385898Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Зафиксируем random_seed в нашем документе","metadata":{}},{"cell_type":"code","source":"def set_random_seed(seed):\n    torch.backends.cudnn.deterministic = True\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \n    \nset_random_seed(306)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:02.046946Z","iopub.execute_input":"2022-03-21T23:53:02.047695Z","iopub.status.idle":"2022-03-21T23:53:02.056410Z","shell.execute_reply.started":"2022-03-21T23:53:02.047655Z","shell.execute_reply":"2022-03-21T23:53:02.055722Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка данных \n\nЗапросим у пользователя креды для подключения к репозиторию","metadata":{}},{"cell_type":"code","source":"login = input('Enter your login: ')\npassword = getpass('Enter the secret value: ')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:04.373941Z","iopub.execute_input":"2022-03-21T23:53:04.374209Z","iopub.status.idle":"2022-03-21T23:53:14.485209Z","shell.execute_reply.started":"2022-03-21T23:53:04.374178Z","shell.execute_reply":"2022-03-21T23:53:14.484486Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Подключимся к репозиторию","metadata":{}},{"cell_type":"code","source":"repo_path = \"IgorLukhnev/FarFetchRS\"\n# Запишем токен в переменную окружения\ng_token = os.getenv('GITHUB_TOKEN', password)\n# Вополним коннект\ng = gh(g_token)\n# Подключимся к репо\nrepo = g.get_repo(repo_path)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:20.514120Z","iopub.execute_input":"2022-03-21T23:53:20.514548Z","iopub.status.idle":"2022-03-21T23:53:20.879163Z","shell.execute_reply.started":"2022-03-21T23:53:20.514493Z","shell.execute_reply":"2022-03-21T23:53:20.878459Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Данные будем загружать на основе датасета, подготовленного на этапе EDA","metadata":{}},{"cell_type":"code","source":"dir_path = 'Data/simpleCat'\ndata_path = 'Data/simpleCat/final_data.csv'\ncontents = repo.get_contents(dir_path)\nfor x in contents:\n    if x.path == data_path:\n        data = pd.read_csv(StringIO(base64.b64decode(repo.get_git_blob(x.sha).content).decode(\"utf8\"))).drop(columns=['Unnamed: 0'])\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:20.882455Z","iopub.execute_input":"2022-03-21T23:53:20.884201Z","iopub.status.idle":"2022-03-21T23:53:28.089427Z","shell.execute_reply.started":"2022-03-21T23:53:20.882997Z","shell.execute_reply":"2022-03-21T23:53:28.088675Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Датасет для моделей ","metadata":{}},{"cell_type":"markdown","source":"Для начала научимся работать с датасетом для переноса обучения - clothing-dataset-full (содержит 5000 изображений одежды по 20 лейблам). На данном датасете мы дообучим несколько моделей:\n1. ResNet\n2. Inception\n3. VGG-16\n4. MobileNet\n\nНо это в перспективе - сейчас только ResNet\n\nВ таком случае создаем класс для датасета","metadata":{}},{"cell_type":"code","source":"class LearningDataset(torch.utils.data.Dataset):\n    def __init__(self, data_dir, transform, data_labels):\n        '''\n        data_dir - путь к директории, где лежат изображения\n        transform - объект для трансформации изображений\n        data_labels - датафрейм для мэппинга картинок с классами\n        '''\n        self.data_dir = data_dir\n        self.transform = transform\n        self.data_labels = data_labels\n        # Создаем словарь для перевода класса в цифровой формат\n        l2int = {l: i for i, l in enumerate(data_labels['label'].unique().tolist())}\n        self.l2int = l2int\n    \n    def __getitem__(self, idx):\n        label = self.data_labels.iloc[idx, 2]\n        img_name = self.data_labels.iloc[idx, 0]\n        path = os.path.join(self.data_dir, img_name + '.jpg')\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            img = img.convert('RGB')\n            if self.transform is not None:\n                img = self.transform(img)\n            return img, self.l2int[label]\n    \n    def __len__(self):\n        return self.data_labels.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:28.090912Z","iopub.execute_input":"2022-03-21T23:53:28.091875Z","iopub.status.idle":"2022-03-21T23:53:28.102470Z","shell.execute_reply.started":"2022-03-21T23:53:28.091830Z","shell.execute_reply":"2022-03-21T23:53:28.101399Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Так, подождите - нужно реализовать еще трансформер.","metadata":{}},{"cell_type":"code","source":"batch_size = 64\n\ntrain_transform = transforms.Compose(\n    [\n     transforms.Resize(224), # меняем размер изображения\n     transforms.RandomHorizontalFlip(p=0.5), # половину изображений перевернем по горизонтали\n     transforms.RandomAdjustSharpness(sharpness_factor=2), # увеличим где-то резкость\n     transforms.RandomAutocontrast(), # применим автоконтраст\n     transforms.RandomCrop(200), # часть фотографий обрежем немного\n     transforms.Resize(224), # часть фотографий и снова растянем\n     transforms.ToTensor(), # преобразуем в тензор\n     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                          std=[0.229, 0.224, 0.225]) # нормализуем значения пикселей по цветовым слоям\n    ]\n    )\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:28.105094Z","iopub.execute_input":"2022-03-21T23:53:28.105455Z","iopub.status.idle":"2022-03-21T23:53:28.115886Z","shell.execute_reply.started":"2022-03-21T23:53:28.105413Z","shell.execute_reply":"2022-03-21T23:53:28.115157Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка модели","metadata":{}},{"cell_type":"markdown","source":"Теперь мы готовы к загрузке модели и ее дообучению\n\nЗагружаем ResNet50 предобученную на ImageNet, заменяем выходной слой, чтобы он выдавал ответ на 20 значений, а не 1000","metadata":{}},{"cell_type":"code","source":"resnet = torchvision.models.resnet50(pretrained=True)\n\nresnet.fc = nn.Linear(in_features=2048, out_features=20, bias=True)\n\nprint(resnet)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:28.117963Z","iopub.execute_input":"2022-03-21T23:53:28.118784Z","iopub.status.idle":"2022-03-21T23:53:31.170047Z","shell.execute_reply.started":"2022-03-21T23:53:28.118756Z","shell.execute_reply":"2022-03-21T23:53:31.169321Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Функции обучения","metadata":{}},{"cell_type":"markdown","source":"Напишем функцию для обучения 1 эпохи модели","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n    '''\n    model - сама модель\n    train_dataloader - загрузчик данных батчами\n    criterion - функционал потерь\n    optimizer - метод оптимизации функционала потерь\n    device - процессор, на котором выполняются вычисления\n    '''\n    model.train()\n    losses = 0\n    for X_train, y_train in tqdm(train_dataloader):\n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        # обнуляем градиенты оптимизатора, чтобы он считал только по данному шагу\n        optimizer.zero_grad()\n        # получаем ответы модели\n        y_pred = model(X_train)\n        loss = criterion(y_pred, y_train)\n        # считаем градиенты\n        loss.backward()\n        optimizer.step()\n        losses += loss.data.item()\n    return losses / len(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:31.171196Z","iopub.execute_input":"2022-03-21T23:53:31.171998Z","iopub.status.idle":"2022-03-21T23:53:31.179742Z","shell.execute_reply.started":"2022-03-21T23:53:31.171956Z","shell.execute_reply":"2022-03-21T23:53:31.179031Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Функция для предсказывания ответов модели","metadata":{}},{"cell_type":"code","source":"def predict(model, val_dataloader, criterion, device=\"cuda:0\"):\n    '''\n    model - сама модель\n    val_dataloader - загрузчик данных батчами\n    criterion - функционал потерь\n    device - процессор, на котором выполняются вычисления\n    '''\n    model.to(device)\n    model.eval()\n    losses = np.array([])\n    predicted_classes = np.array([])\n    true_classes = np.array([])\n    with torch.no_grad():\n        for X_val, y_val in tqdm(val_dataloader):\n            X_val = X_val.to(device)\n            y_val = y_val.to(device)\n            y_pred = model(X_val)\n            losses= np.append(losses, \n                              criterion(y_pred, y_val).to('cpu').detach().numpy())\n            predicted_classes = np.append(predicted_classes, \n                                          torch.max(F.softmax(y_pred, dim=1), dim=1)[1].to('cpu').detach().numpy())\n            true_classes = np.append(true_classes,\n                                     y_val.to('cpu').detach().numpy())\n    return losses, predicted_classes, true_classes","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:31.181077Z","iopub.execute_input":"2022-03-21T23:53:31.181353Z","iopub.status.idle":"2022-03-21T23:53:31.192706Z","shell.execute_reply.started":"2022-03-21T23:53:31.181316Z","shell.execute_reply":"2022-03-21T23:53:31.191881Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Ну и наконец, само обучение","metadata":{}},{"cell_type":"code","source":"def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n    '''\n    model - сама модель\n    train(val)_dataloader - загрузчик данных батчами\n    criterion - функционал потерь\n    optimizer - метод оптимизации функционала потерь\n    device - процессор, на котором выполняются вычисления\n    n_epochs - число эпох обучения\n    scheduler - объект, уменьшающий шаг оптимизатора\n    '''\n    model.to(device)\n    train_loss = []\n    losses = []\n    val_losses = []\n    for epoch in range(n_epochs):\n        train_loss = train_one_epoch(\n            model, train_dataloader, criterion, optimizer, device=device)\n        losses.append(train_loss)\n        clear_output(True)\n        losses_, preds, y_val = predict(model, val_dataloader, criterion, \n                                        device=device)\n\n        val_loss = np.mean(losses_)\n        val_losses.append(val_loss)\n        val_accuracy = accuracy_score(y_val, preds)\n        if scheduler is not None:\n            scheduler.step(val_accuracy)\n        plt.plot(range(epoch + 1), losses, marker='o', label='Train')\n        plt.plot(range(epoch + 1), val_losses, c='r', marker='x', label='Val')\n        plt.title(f'Cross-Entropy во время обучения')\n        plt.xlabel('Эпоха')\n        plt.ylabel('CE')\n        plt.legend()\n        plt.show()\n        print(\n            f'''{epoch + 1} эпоха; Train CE = {losses[-1]};\\nVal CE = {val_losses[-1]};\nVal accuracy = {val_accuracy}''')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T23:53:31.193953Z","iopub.execute_input":"2022-03-21T23:53:31.194219Z","iopub.status.idle":"2022-03-21T23:53:31.206079Z","shell.execute_reply.started":"2022-03-21T23:53:31.194186Z","shell.execute_reply":"2022-03-21T23:53:31.205328Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Дообучение","metadata":{}},{"cell_type":"markdown","source":"Инициализируем все объекты, которые нам пригодятся для обучения","metadata":{}},{"cell_type":"code","source":"bad_imgs = [\n    'c60e486d-10ed-4f64-abab-5bb698c736dd', \n    '040d73b7-21b5-4cf2-84fc-e1a80231b202',\n    '784d67d4-b95e-4abb-baf7-8024f18dc3c8',\n    '1d0129a1-f29a-4a3f-b103-f651176183eb',\n    'd028580f-9a98-4fb5-a6c9-5dc362ad3f09',\n           ]\n\ndata_labels = pd.read_csv('../input/clothing-dataset-full/images.csv')\n\ndata_labels.drop(index=data_labels[data_labels['image'].apply(lambda x: x in bad_imgs)].index, inplace=True)\n\ndata_labels.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T00:05:13.991200Z","iopub.execute_input":"2022-03-22T00:05:13.991904Z","iopub.status.idle":"2022-03-22T00:05:14.007828Z","shell.execute_reply.started":"2022-03-22T00:05:13.991864Z","shell.execute_reply":"2022-03-22T00:05:14.007165Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"train_data_path = '../input/clothing-dataset-full/images_compressed'\n\noptimizer = torch.optim.Adam(resnet.parameters())\ncriterion = nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max')\nn_epochs = 10\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\ntrain_dataset = LearningDataset(train_data_path, transform=train_transform, data_labels=data_labels)\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, \n                                               batch_size=batch_size, \n                                               shuffle=True)\nval_dataloader = torch.utils.data.DataLoader(train_dataset, \n                                             batch_size=batch_size,\n                                             shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T00:12:40.795181Z","iopub.execute_input":"2022-03-22T00:12:40.795817Z","iopub.status.idle":"2022-03-22T00:12:40.805113Z","shell.execute_reply.started":"2022-03-22T00:12:40.795778Z","shell.execute_reply":"2022-03-22T00:12:40.804363Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Запустим обучение на 10 эпохах","metadata":{}},{"cell_type":"code","source":"train(resnet, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T00:12:44.097618Z","iopub.execute_input":"2022-03-22T00:12:44.098413Z","iopub.status.idle":"2022-03-22T00:35:19.171317Z","shell.execute_reply.started":"2022-03-22T00:12:44.098361Z","shell.execute_reply":"2022-03-22T00:35:19.170642Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"Отлично, модель обучена - нужно сохранить ее конфигурацию, чтобы затем использовать в будущих документах","metadata":{}},{"cell_type":"code","source":"torch.save(resnet.state_dict(), 'resnet_on_clothing_tuned')","metadata":{"execution":{"iopub.status.busy":"2022-03-22T00:42:00.433908Z","iopub.execute_input":"2022-03-22T00:42:00.434335Z","iopub.status.idle":"2022-03-22T00:42:00.597076Z","shell.execute_reply.started":"2022-03-22T00:42:00.434300Z","shell.execute_reply":"2022-03-22T00:42:00.596357Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Окей, давайте пробовать получать значения признаков для наших данных","metadata":{}},{"cell_type":"markdown","source":"## Генерация признаков ","metadata":{}},{"cell_type":"code","source":"mask = (data['sex'] == 'm') & (data['cat'] == 'clothing') & (data['category1'] == 'trousers')\n\ntest_dir = '../input/farfetch-male-trousers/m_clothing_trousers'\n\ntest_labels = data.reset_index().loc[mask, 'index'].rename({'index': 'img'}, axis=1)\nlabels = test_labels.to_numpy().reshape(6412, 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:08:18.965366Z","iopub.execute_input":"2022-03-22T01:08:18.965810Z","iopub.status.idle":"2022-03-22T01:08:19.137449Z","shell.execute_reply.started":"2022-03-22T01:08:18.965772Z","shell.execute_reply":"2022-03-22T01:08:19.136732Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# Берем все слои сети кроме последнего\nmodules = list(resnet.children())[:-1]\n# Создаем генератор признаков\ngenerator = nn.Sequential(*modules)\n# Запрещаем накапливать градиенты\nfor p in generator.parameters():\n    p.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-03-22T00:55:31.759961Z","iopub.execute_input":"2022-03-22T00:55:31.760235Z","iopub.status.idle":"2022-03-22T00:55:31.766133Z","shell.execute_reply.started":"2022-03-22T00:55:31.760206Z","shell.execute_reply":"2022-03-22T00:55:31.765091Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"i = 0\nfor l in tqdm(labels):\n    with open(f'../input/farfetch-male-trousers/m_clothing_trousers/{l.item()}.jpg', 'rb') as img_stream:\n        img = Image.open(img_stream)\n        img = img.convert('RGB')\n        img = train_transform(img).unsqueeze(0).to(device)\n        gens = generator(img)\n        if i == 0:\n            features = gens.squeeze(3).squeeze(2).squeeze(0).detach().to('cpu').numpy()\n        else:\n            features = np.vstack([features, gens.squeeze(3).squeeze(2).squeeze(0).detach().to('cpu').numpy()])\n        i += 1\n#         print(generator(img.unsqueeze(0).to(device)).squeeze(3).squeeze(2).squeeze(0).detach().to('cpu').numpy())","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:19:50.122443Z","iopub.execute_input":"2022-03-22T01:19:50.123051Z","iopub.status.idle":"2022-03-22T01:23:10.025486Z","shell.execute_reply.started":"2022-03-22T01:19:50.123011Z","shell.execute_reply":"2022-03-22T01:23:10.024664Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"features.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:23:10.027485Z","iopub.execute_input":"2022-03-22T01:23:10.027779Z","iopub.status.idle":"2022-03-22T01:23:10.033069Z","shell.execute_reply.started":"2022-03-22T01:23:10.027742Z","shell.execute_reply":"2022-03-22T01:23:10.032428Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"new_features = pd.DataFrame(np.hstack([labels, features])).set_index(new_features[0].astype(int)).drop(columns=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:28:48.223884Z","iopub.execute_input":"2022-03-22T01:28:48.224152Z","iopub.status.idle":"2022-03-22T01:28:48.348916Z","shell.execute_reply.started":"2022-03-22T01:28:48.224121Z","shell.execute_reply":"2022-03-22T01:28:48.348140Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"to_save = new_features.drop(columns=new_features.sum()[new_features.sum() == 0].index)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:29:11.713274Z","iopub.execute_input":"2022-03-22T01:29:11.713555Z","iopub.status.idle":"2022-03-22T01:29:11.812806Z","shell.execute_reply.started":"2022-03-22T01:29:11.713523Z","shell.execute_reply":"2022-03-22T01:29:11.812057Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"to_save","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:29:13.300253Z","iopub.execute_input":"2022-03-22T01:29:13.300954Z","iopub.status.idle":"2022-03-22T01:29:13.338137Z","shell.execute_reply.started":"2022-03-22T01:29:13.300916Z","shell.execute_reply":"2022-03-22T01:29:13.337386Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"initial_data = data.loc[mask, :]","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:26:18.367222Z","iopub.execute_input":"2022-03-22T01:26:18.367486Z","iopub.status.idle":"2022-03-22T01:26:18.374322Z","shell.execute_reply.started":"2022-03-22T01:26:18.367456Z","shell.execute_reply":"2022-03-22T01:26:18.373616Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"final_data = pd.concat([initial_data, to_save], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:31:27.677281Z","iopub.execute_input":"2022-03-22T01:31:27.677570Z","iopub.status.idle":"2022-03-22T01:31:27.699722Z","shell.execute_reply.started":"2022-03-22T01:31:27.677537Z","shell.execute_reply":"2022-03-22T01:31:27.699066Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"final_data.to_csv('data_image_embedding.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:32:29.642370Z","iopub.execute_input":"2022-03-22T01:32:29.642937Z","iopub.status.idle":"2022-03-22T01:32:35.367172Z","shell.execute_reply.started":"2022-03-22T01:32:29.642898Z","shell.execute_reply":"2022-03-22T01:32:35.366344Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}